<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Instructor: Ben Sherman from Weights and Biases
What are AI ML and DL?  Deep learning is a specific form of machine learning."><title>ðŸª´ Vik's Notes</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://notes.vsekar.com//icon.png><link href=https://notes.vsekar.com/styles.706bb6073ba85d26809f9096dae23a6b.min.css rel=stylesheet><link href=https://notes.vsekar.com/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://notes.vsekar.com/js/darkmode.b4dd02a8c7f089554384882ceaa8a4bb.min.js></script>
<script src=https://notes.vsekar.com/js/util.5e39932758f9ecaf45fd54506ed61416.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://notes.vsekar.com/js/popover.6da9b273c092cc16fc1aa904d71a2163.min.js></script>
<script src=https://notes.vsekar.com/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://notes.vsekar.com/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://notes.vsekar.com/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://notes.vsekar.com/",fetchData=Promise.all([fetch("https://notes.vsekar.com/indices/linkIndex.1ebff6af5a6c14f1af474648237f19c6.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://notes.vsekar.com/indices/contentIndex.bab58709a3c040ac9901334918721b1d.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://notes.vsekar.com",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://notes.vsekar.com",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/notes.vsekar.com\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-5N9RQH0WPK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-5N9RQH0WPK",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://notes.vsekar.com/js/full-text-search.51f0b1753e9b30839d053f8a98cc20d1.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://notes.vsekar.com/>ðŸª´ Vik's Notes</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Mar 28, 2023</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><ol><li><a href=#what-are-ai-ml-and-dl>What are AI ML and DL?</a></li><li><a href=#why-deep-learning>Why deep learning?</a></li><li><a href=#ml-as-an-api>ML as an API</a></li><li><a href=#perceptrons>Perceptrons</a></li></ol></li></ol></nav></details></aside><p>Instructor: Ben Sherman from Weights and Biases</p><a href=#what-are-ai-ml-and-dl><h3 id=what-are-ai-ml-and-dl><span class=hanchor arialabel=Anchor># </span>What are AI ML and DL?</h3></a><ul><li>Deep learning is a specific form of machine learning. Machine learning is a specific for of Artificial Intelligence.</li><li>Machine learning:<ul><li>dont define rule based conditional frameworks that AI should respond to</li><li>ML takes data and learns to respond to scenarios based on it</li><li>Goal is to imitate human behavior</li></ul></li><li>Systems that learn intelligently from data</li></ul><blockquote><p>Within a generation, the problem of creating artificial intelligence will be substantially solved- Marvin Minsky, 1967</p></blockquote><blockquote><p>Overwhelming majority of what we call intelligence is developed bu the endo f the first year of life. Marvin minsky, 1977</p></blockquote><ul><li><p>Don&rsquo;t program actions, but learn what the best program action is</p></li><li><p>Other class of models: Tree based models</p><ul><li>dont program symbolic rules, but learn the symbolic rules</li><li>what kind of symbols are you looking for? (green pixel?)</li><li>What is the threshold number of occurances to make decision (no of green pixes)</li><li>Decide if stop light or tree</li></ul></li><li><p>Other class: Linear Models</p><ul><li>Harness the power of linear algebra, vectors, planes, projections, etc. xkcd.com/1838</li></ul></li><li><p>Deep learning: put simple pieces together to make something complex (deep)</p></li></ul><a href=#why-deep-learning><h3 id=why-deep-learning><span class=hanchor arialabel=Anchor># </span>Why deep learning?</h3></a><ul><li>DL obeys the LEGO principle<ul><li>make complex things by combining simple pieces</li><li>make interoperable simple things and then build worlds</li><li>LEGO API:<ul><li>Studs on top of brick</li><li>Holes on bottom</li></ul></li><li>The lego analogy is so good that things being matched are called &ldquo;shapes&rdquo;<ul><li>Matrix multiplication function</li><li>Activation function</li></ul></li><li>Matrix + activation func = fully connected layer</li><li>fully connected layer + fully connected layer = multilayer perceptron</li><li>Lego principle in action = Inception V1 Szegedy et all 2014<ul><li>Used initially for image classification</li></ul></li></ul></li><li>DL scales well with data &ndash;> more data = more accurate.<ul><li>this does not happen with tree-models, or older methods<ul><li>cannot program infinitely many if statements</li></ul></li><li>DL can learn from more data, and get better</li><li>Older models dont get better with more data</li><li>Imagine how well DL can train with internet data<ul><li>powers openAI and text-to-image AI</li></ul></li><li>We are only limited by amount of data available, and how we can fit into a computer</li></ul></li><li>Linear algebra is all you need for graphics, and GPUs are excellent accelerators. They are very valuable for DL acceleration too!<ul><li>Python allows for accelerated DL</li><li>High performance and full flexibility can all be done in python</li><li>Have bindings to C++ using CUDA on nVidia GPUs</li></ul></li><li>Pytorch<ul><li>came from Meta</li><li>Pytorch lightning is a nice framework for python</li><li>CuDNN is low level operations for array operations in DL</li><li>CUDA (c/c++) is low level operations</li></ul></li><li>Two major frameworks:<ul><li>Tensorflow / Keras &ndash; Google</li><li>Jax &ndash; Google</li><li>Pytorch / Lightning &ndash; Facebook</li></ul></li><li>Pytorch is more popular among researchers and is more DIY than Keras<ul><li>used more and more these days</li></ul></li><li>Pytorch lightning tends to make it more like Keras</li><li>Tensorflow has more mature tooling for edge cases really, but Pytorch is catching up</li></ul><a href=#ml-as-an-api><h3 id=ml-as-an-api><span class=hanchor arialabel=Anchor># </span>ML as an API</h3></a><ul><li><p>API tells us it does something without telling us how</p></li><li><p>3 methods / functions</p><ul><li>Loss<ul><li>inspect model predictions, and says how good the model is doing in predictions</li><li>measure of prediction quality</li><li>You have a predetermined cat dataset; how well does AI predict that.</li></ul></li><li>Model.forward<ul><li>A forward pass through the large computational graph that constitutes the learning system</li></ul></li><li>Model.fit<ul><li>takes examples in, makes model better</li><li>use a known dataset to train the model</li></ul></li></ul></li><li><p>3 types of API</p><ul><li>Model &ndash; the AI of the system</li><li>Inputs &ndash; kind of data model takes in (images, 3d scans)</li><li>Targets &ndash; kind of data you predict with Model, or Model output</li></ul></li><li><p>Training and deployment &ndash; think of it as development and production</p></li><li><p>First do model.fit to teach the DL system</p></li><li><p>loss is like a testing/CI that tells you how well you are doing</p></li><li><p>model.forward is to use it in production</p></li><li><p>Inputs and targets are both kinds of data</p><ul><li>inputs: data model sees and uses to make decisions<ul><li>determined by what data you have</li></ul></li><li>targets: data model is trying to produce, only seen during training<ul><li>determined by the problem (cats or not cats)</li></ul></li><li>Need both during training phase</li><li>But in production, you will not have targets, only inputs</li></ul></li><li><p>Example: feed grams vs chicken weight</p><ul><li>Linear regression is enough. Still a type of ML!</li><li>Use loss to &ldquo;score&rdquo; the model. Lower is better.</li><li>Prediction comes from model.forward</li><li>compare that to the known correct value</li><li>Calculate loss (rms error is one kind)</li></ul></li><li><p>One hot vector &ndash; vectorized representation of the correct answer.</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>trained_model</span> <span class=o>=</span> <span class=n>Model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>training_inputs</span><span class=p>,</span> <span class=n>known_outputs</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Using fit to make a model better</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>untrained_model</span> <span class=o>=</span> <span class=n>Model</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>untrained_outputs</span> <span class=o>=</span> <span class=n>untrained_model</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>training_inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>untrained_loss</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>untrained_outputs</span><span class=p>,</span> <span class=n>training_targets</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>trained_model</span> <span class=o>=</span> <span class=n>untrained_model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>training_inputs</span><span class=p>,</span> <span class=n>training_targets</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>When is a model good?</p><ul><li>Make sure that loss in production is better than a certain number.</li></ul><a href=#perceptrons><h3 id=perceptrons><span class=hanchor arialabel=Anchor># </span>Perceptrons</h3></a><p>Digit recognition problem is the helloworld of ML!</p><ul><li>Could you identify handwritten digits using Python?</li><li>Rules based methods based on conditions will not work for something like this</li></ul><p>Frank Rosenblatt invented the perceptron 1960 to solve such problems. How did his machine work?</p><ul><li>uses variable resistors whose value can be set by knobs, and a light that turns on</li><li>Imagine you have a knob for each pixel in image of 5</li><li>Set the knobs so that light turns on when the number is 5</li><li>You just trained the perceptron</li></ul><p>Mathematical model of a perceptron</p><ul><li>Multiply each input by a weight (like the knobs)</li><li>Sum all the weighted inputs</li><li>Pass the sum through an activation function (like the lightbulb)</li></ul><p>First two steps is the dot product of the input vector and weight vector. You can add a constant to it if needed. This simple linalg solves super fast on GPU</p><p>In pytorch, this is called a <code>Linear</code> block.</p><ul><li>Break the input dataset into batches (like 32 out the 1000)<ul><li>this is needed because datasets can be really really big</li></ul></li><li>Dataloaders do this, the behave like lists</li><li>One pass through of entire dataset while adjusting weights in reponse to the inputs is called an <mark>epoch</mark></li><li></li></ul><p>Use <code>Trainer.fit</code> in pytorch lightning to do the fit.</p><ul><li>Iterates over Dataloader</li><li>calls <mark>Optimizer</mark> to set the weights</li><li>minimizes loss</li></ul><p>Sigmoid (S-shaped) functions work much better than linear activation functions</p><p>Recognizing structures and patterns in data is known as <mark>feature detection</mark>. Example, the strokes involved in creating the number 5. horizontal line on top, vertical line on left, and backwards C shape.</p><p>So train a model for each of the three features. A fully connected layer (perceptron + act func) to detect horizontal line, vertical line and backwards C. Connect all the 3 fully connected layers, to create a multilayer perceptron to detect a 5. In Pytorch this is done using <code>Sequential</code></p><p>But how do we modify this to increase dimensionality of the outputs? Dont just identify the digit (5 or not) but tell me the digit it is. This is where we need probablity calculation. This is done using <code>softmax</code> function. Take the multidimensional output and run it through softmax.</p><p>Softmax gives you an array of probabilities. But we want an array of zeros and ones. to finally identify the digit. RMS error is a bad way to compare this and has high error. People mostly use the <mark>cross entropy</mark> function.</p><p><a href=https://ml-cheatsheet.readthedocs.io rel=noopener>https://ml-cheatsheet.readthedocs.io</a></p><p>How does the .fit work?</p><ul><li><p>All neural network fitting schemes uses local optimization. Descend the surface of the loss function. Uses calculus to descend the loss function surface. Compute gradient of loss function wrt any given point on the surface. Then follow that till gradient is zero. Gradient descent algorithm.</p></li><li><p>Downside to local optimization can always give false minima</p></li><li><p>Gradient descent algorithm possibly with &ldquo;Momentum&rdquo; is usually the first choice for optimizers. Sometimes ADAM or RMSProp works better.</p></li><li><p>Recommendation: better to try different optimizers, than mess with config of optimizer you are using.</p></li><li><p>Look into Backpropagation algorithm too, its really beautiful mathematically. OpenAI blog post has a great article. This blog is also very good for ML. Also mentioned 3blue1brown videos -> Look at his deep learning videos.</p></li><li><p>Batchnorm &ndash; normalize the inputs to be within some some range of numbers, so that activation functions dont become unresponsive</p></li></ul><p>2 minute courses &ndash; research topics
fastAI - courses on YT and notebooks
full stack deep learning course YT
weights and biases YT</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://notes.vsekar.com/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Vikram Sekar using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2024</p><ul><li><a href=https://notes.vsekar.com/>Home</a></li><li><a href=https://twitter.com/vikramskr>Twitter</a></li><li><a href=https://github.com/vik-s>Github</a></li></ul></footer></div></div></body></html>